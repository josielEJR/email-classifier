# üìß Classificador de Emails com IA  
Produtivo x Improdutivo + Resposta Autom√°tica + Lote (at√© 6 arquivos)

Este projeto √© uma aplica√ß√£o web que:

1. **L√™ emails** (texto colado, `.txt` ou `.pdf` ou arquivos dropados);
2. **Classifica** cada email em:
   - `Produtivo` (quando exige a√ß√£o/resposta)
   - `Improdutivo` (mensagens de cortesia, agradecimentos etc.)
3. **Gera uma resposta autom√°tica** em portugu√™s usando **OpenAI GPT**;
4. **Processa v√°rios emails em lote** (at√© **6 arquivos** de uma vez) e exibe:
   - Categoria por arquivo
   - Resumo da resposta sugerida
   - Bot√£o **‚ÄúCopiar resposta‚Äù** por linha.

Projeto desenvolvido como solu√ß√£o para um **desafio de processo seletivo** na √°rea de IA / automa√ß√£o de atendimento.

---

## üß± Tecnologias utilizadas

- **Backend**
  - Python 3
  - FastAPI + Uvicorn
  - scikit-learn (TF-IDF + Logistic Regression)
  - NLTK (stopwords em portugu√™s)
  - pdfplumber (extra√ß√£o de texto de PDF)
  - OpenAI (modelo GPT para gerar respostas)
  - python-dotenv (carregar vari√°veis de ambiente, ex.: `OPENAI_API_KEY`)

- **Frontend**
  - HTML, CSS, JavaScript puro
  - UI com:
    - Abas: **Texto** / **Arquivo(s)**
    - Drag & drop para upload
    - Cards de resultado
    - Tabela de resultados em lote com bot√£o **Copiar** por linha
    - Hist√≥rico local (localStorage)
    - Estat√≠sticas r√°pidas (total, produtivos, improdutivos)
    - Toasts / feedback visual

---

## üìÅ Estrutura do projeto

```bash
email-classifier/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py          # API FastAPI (classifica√ß√£o + GPT + batch)
‚îÇ   ‚îî‚îÄ‚îÄ train_model.py   # Script para treinar e salvar o modelo (model.pkl)
‚îú‚îÄ‚îÄ web/
‚îÇ   ‚îú‚îÄ‚îÄ index.html       # Interface web (tabs Texto/Arquivo + lote)
‚îÇ   ‚îú‚îÄ‚îÄ styles.css       # Estilos
‚îÇ   ‚îî‚îÄ‚îÄ app.js           # L√≥gica JS (√∫nico vs. lote, tabela, hist√≥rico, etc.)
‚îú‚îÄ‚îÄ requirements.txt     # Depend√™ncias Python
‚îî‚îÄ‚îÄ README.md            # Este arquivo
```

---

## ‚úÖ Pr√©-requisitos

- Python 3.9+
- `pip` (gerenciador de pacotes)
- (Opcional, mas recomendado) `venv` / `virtualenv`

Verifica√ß√£o r√°pida no Linux/Ubuntu:

```bash
python3 --version
pip --version
```

---

## üîß 1. Clonar o reposit√≥rio

```bash
git clone https://github.com/josielEJR/email-classifier.git
cd email-classifier
```

> Substitua `josielEJR` pelo seu usu√°rio real do GitHub.

---

## üêç 2. Criar e ativar o ambiente virtual

```bash
python3 -m venv venv
source venv/bin/activate        # Linux / macOS

# No Windows (PowerShell):
# .\venv\Scripts\Activate.ps1
```

Quando o ambiente estiver ativo, o terminal geralmente mostra `(venv)` no in√≠cio da linha.

---

## üì¶ 3. Instalar depend√™ncias

```bash
pip install -r requirements.txt
```

---

## üß† 4. Treinar o modelo de classifica√ß√£o

O modelo (TF-IDF + Logistic Regression) √© treinado em um conjunto simples de exemplos para diferenciar **emails produtivos** x **improdutivos**.

```bash
python3 app/train_model.py
```

Se tudo der certo, ser√° gerado o arquivo:

```bash
app/model.pkl
```

> ‚ö†Ô∏è Importante: se esse arquivo **n√£o existir**, o backend n√£o sobe.  
> Sempre rode o `train_model.py` pelo menos uma vez antes de iniciar a API.

---

## üîë 5. Configurar a chave da OpenAI (`OPENAI_API_KEY`)

A aplica√ß√£o l√™ a chave via vari√°vel de ambiente (pode estar num `.env`).

### Op√ß√£o A ‚Äì Exportar direto no terminal

```bash
export OPENAI_API_KEY="SUA_CHAVE_AQUI"
```

Conferir:

```bash
echo $OPENAI_API_KEY
```

### Op√ß√£o B ‚Äì Arquivo `.env`

Crie um arquivo `.env` na raiz (`email-classifier/.env`):

```env
OPENAI_API_KEY=SUA_CHAVE_AQUI
```

O `main.py` usa `python-dotenv` para carregar essa vari√°vel.

---

## üöÄ 6. Subir o backend (API FastAPI)

Na raiz do projeto, com o venv ativo:

```bash
uvicorn app.main:app --reload
```

Sa√≠da esperada:

```text
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
INFO:     Application startup complete.
```

### Endpoints principais

- `GET /`  
  ‚Üí Serve a interface web (`index.html`).

- `POST /process`  
  ‚Üí Recebe **texto ou 1 arquivo** (`text` ou `file`) e retorna:
  ```json
  {
    "categoria": "Produtivo" | "Improdutivo",
    "resposta": "texto sugerido pelo GPT ou fallback",
    "texto_extraido": "trecho do email"
  }
  ```

- `POST /process_batch`  
  ‚Üí Recebe **v√°rios arquivos** (`files`) e retorna:
  ```json
  {
    "resultados": [
      {
        "filename": "email_1.txt",
        "categoria": "Produtivo",
        "resposta": "resposta sugerida",
        "preview": "trecho do texto analisado"
      },
      ...
    ]
  }
  ```

Se a chamada √† OpenAI falhar, o backend devolve uma **resposta padr√£o** (fallback), diferente para Produtivo e Improdutivo, para nunca ficar ‚Äúsem resposta‚Äù.

---

## üåê 7. Subir o frontend (interface web)

Em outro terminal / aba:

```bash
cd web
python3 -m http.server 5500
```

Sa√≠da esperada:

```text
Serving HTTP on 0.0.0.0 port 5500 ...
```

Acesse:

- Aplica√ß√£o: `http://127.0.0.1:8000/`

> O FastAPI j√° est√° preparado para servir o `index.html` na raiz (`/`).

---

## üß™ 8. Testando a aplica√ß√£o

### üîπ Modo 1 ‚Äì Texto (aba **Texto**)

Exemplo de email **produtivo**:

> Bom dia, estou com problema para acessar o sistema e preciso de uma atualiza√ß√£o sobre a minha solicita√ß√£o de suporte.

1. V√° na aba **Texto**  
2. Cole o texto  
3. Clique em **Processar**

Resultado esperado:

- Categoria: **Produtivo**
- Card amarelo com mensagem de que requer a√ß√£o
- Resposta sugerida (GPT ou fallback)
- Texto analisado dispon√≠vel em ‚ÄúTexto analisado‚Äù.

---

### üîπ Modo 2 ‚Äì Arquivo √∫nico (aba **Arquivo(s)**)

1. V√° na aba **Arquivo(s)**
2. Arraste um `.txt` ou `.pdf` ou clique para selecionar
3. Clique em **Processar**

A l√≥gica √© a mesma do modo Texto, mas o backend primeiro extrai o conte√∫do do arquivo.

---

### üîπ Modo 3 ‚Äì M√∫ltiplos arquivos / lote (aba **Arquivo(s)**)

1. Ainda na aba **Arquivo(s)**, selecione **at√© 6 arquivos** `.txt` ou `.pdf`  
   - via drag & drop  
   - ou segurando `Ctrl`/`Shift` ao selecionar
2. O contador mostra algo como: `6 arquivos selecionados`
3. Clique em **Processar**

A aplica√ß√£o:

- Chama o endpoint `/process_batch`
- Preenche a se√ß√£o **‚ÄúResultados dos Arquivos‚Äù** com uma tabela contendo:
  - `#` (√≠ndice)
  - `Arquivo`
  - `Categoria`
  - `Resposta sugerida (resumo)`
  - Bot√£o **‚ÄúCopiar resposta‚Äù** por linha

Cada item do lote tamb√©m atualiza:

- Estat√≠sticas (total, produtivos, improdutivos)
- Hist√≥rico local (com limite de itens)

---

## üì° 9. Testando a API diretamente (Postman / cURL)

### a) Texto direto

```bash
curl -X POST http://127.0.0.1:8000/process \
  -F "text=Estou com dificuldade para acessar o portal, poderiam verificar?"
```

### b) 1 arquivo `.txt` ou `.pdf`

```bash
curl -X POST http://127.0.0.1:8000/process \
  -F "file=@email_exemplo.txt"
```

### c) M√∫ltiplos arquivos (lote)

```bash
curl -X POST http://127.0.0.1:8000/process_batch \
  -F "files=@email1.txt" \
  -F "files=@email2.txt" \
  -F "files=@email3.txt"
```

---

## üß© 10. Poss√≠veis erros comuns (Troubleshooting)

**1) `RuntimeError: OPENAI_API_KEY n√£o definida`**

- Causa: vari√°vel de ambiente n√£o foi configurada.
- Solu√ß√£o:
  ```bash
  export OPENAI_API_KEY="SUA_CHAVE_AQUI"
  uvicorn app.main:app --reload
  ```

---

**2) `Arquivo de modelo n√£o encontrado em: ... model.pkl`**

- Causa: `train_model.py` ainda n√£o foi rodado.
- Solu√ß√£o:
  ```bash
  python3 app/train_model.py
  ```

---

**3) Frontend abre mas n√£o aparece resposta**

- Verifique se o backend est√° ativo em `http://127.0.0.1:8000`.
- Veja no terminal se est√° chegando requisi√ß√£o:
  ```text
  INFO: 127.0.0.1:XXXXX - "POST /process HTTP/1.1" 200 OK
  ```
- Se aparecer erro 500, normalmente √©:
  - API Key da OpenAI incorreta
  - `model.pkl` ausente ou corrompido

---

## üìå 11. Resumo r√°pido (para avaliadores)

Para rodar localmente:

```bash
git clone https://github.com/SEU_USUARIO/email-classifier.git
cd email-classifier

python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

python3 app/train_model.py

# Definir OPENAI_API_KEY (via .env ou export)
uvicorn app.main:app --reload
```

Acessar:

- Aplica√ß√£o: `http://127.0.0.1:8000/`

Funcionalidades-chave:

- Classifica√ß√£o **Produtivo x Improdutivo**
- Resposta autom√°tica via **GPT** com **fallback** em caso de erro
- Upload de **texto, 1 arquivo ou m√∫ltiplos arquivos (at√© 6)**
- Tabela de resultados em lote com **bot√£o de copiar resposta** por item
- Hist√≥rico e estat√≠sticas de uso no pr√≥prio frontend.
